# ImplementaÃ§Ã£o HÃ­brida MPI e OpenMP para Vizinhos Comuns em Grafos

## ğŸ“Œ DescriÃ§Ã£o
Este projeto implementa uma versÃ£o paralela do cÃ¡lculo de vizinhos comuns em grafos utilizando duas abordagens:

- **MemÃ³ria Compartilhada** com OpenMP
- **MemÃ³ria DistribuÃ­da** com MPI
- **Abordagem HÃ­brida** combinando MPI e OpenMP

O objetivo principal Ã© analisar o impacto da paralelizaÃ§Ã£o no desempenho do algoritmo para diferentes configuraÃ§Ãµes de processamento.

## ğŸ›  Estrutura do DiretÃ³rio

```bash
Hibrido-MPIopeMP/
â”‚â”€â”€ ComputaÃ§Ã£o_Paralela___TP3.pdf  # RelatÃ³rio do trabalho
â”‚â”€â”€ README.md                      # Este arquivo
â”‚â”€â”€ entrada.edgelist                # Arquivo de entrada com a lista de arestas do grafo
â”‚â”€â”€ entrada.cng                      # ConfiguraÃ§Ã£o da entrada
â”‚â”€â”€ tempos.csv                      # Resultados dos tempos de execuÃ§Ã£o
â”‚â”€â”€ graficos.py                      # Script para gerar grÃ¡ficos dos resultados
â”‚â”€â”€ MPIopeMP.c                      # CÃ³digo fonte da implementaÃ§Ã£o hÃ­brida
â”‚â”€â”€ hibrido                          # ExecutÃ¡vel gerado
â”‚â”€â”€ resultado_2p_4t.txt              # Resultados para 2 processos e 4 threads
â”‚â”€â”€ resultado_4p_8t.txt              # Resultados para 4 processos e 8 threads
â”‚â”€â”€ resultado_6p_10t.txt             # Resultados para 6 processos e 10 threads
```

## ğŸš€ Como Compilar e Executar

### ğŸ”¹ CompilaÃ§Ã£o
Para compilar o cÃ³digo hÃ­brido utilizando MPI e OpenMP:
```bash
mpicc -fopenmp -o hibrido MPIopeMP.c
```

### ğŸ”¹ ExecuÃ§Ã£o
Para executar com diferentes nÃºmeros de processos e threads:
```bash
mpirun -np <num_processos> ./hibrido <num_threads> entrada.edgelist
```

Exemplo de execuÃ§Ã£o com 4 processos e 8 threads:
```bash
mpirun -np 4 ./hibrido 8 entrada.edgelist
```

## ğŸ“Š AnÃ¡lise de Resultados
Os resultados sÃ£o armazenados no arquivo `tempos.csv`. Para visualizar os grÃ¡ficos de desempenho, execute:
```bash
python3 graficos.py
```
Os grÃ¡ficos gerados ajudam a compreender o impacto da paralelizaÃ§Ã£o no tempo de execuÃ§Ã£o do algoritmo.

## ğŸ“Œ ConclusÃ£o
Este projeto demonstra o impacto da paralelizaÃ§Ã£o na computaÃ§Ã£o de vizinhos comuns em grafos, explorando as vantagens de diferentes abordagens paralelas. A combinaÃ§Ã£o de MPI e OpenMP mostrou-se eficiente para balancear a carga computacional em diferentes arquiteturas.
